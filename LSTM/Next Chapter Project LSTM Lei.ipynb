{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from itertools import combinations, takewhile\n",
    "import collections\n",
    "from snorkel.labeling import labeling_function,LabelingFunction,LFAnalysis,PandasLFApplier,LFApplier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_topics=pd.read_csv('hot_topics_data_100K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_topics_sampled=hot_topics.sample(n=10000,random_state=666) #all  test first2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence blue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras import backend as K\n",
    "# k.set_learning_phase(1)\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras import initializers\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras.models import Sequential,Model\n",
    "# from keras import layers as Layer\n",
    "# from keras.layers import Dense,LSTM,Dropout,Input,Activation,Add,Concatenate,Embedding\n",
    "# from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.models import load_model\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras\n",
    "import warnings\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    " \n",
    "def clean_body(text):\n",
    "    newText = text.lower()\n",
    "    newText = re.sub('[^\\w\\s\\d\\.]','',newText)\n",
    "    newText = ' '.join(newText.split())\n",
    "    tokens = [w for w in newText.split() if not w in STOP_WORDS]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train=hot_topics_sampled.FINDINGS.apply(lambda r:clean_body(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27340    patient status post right mastectomy reconstruction. abnormal enhancement present right reconstructed breast right axilla.mild background parenchymal enhancement noted left breast. stable postsurgical changes prior breast reduction susceptibility artifact biopsy marker clip site prior benign bre...\n",
       "Name: FINDINGS, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentences_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_highlight(text):\n",
    "    newText = text.lower()\n",
    "    newText = re.sub('[^\\w\\s\\d\\.]','',newText)\n",
    "    newText = ' '.join(newText.split())\n",
    "    newText = '_START_ '+ newText + ' _END_'\n",
    "    return newText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=hot_topics_sampled.IMPRESSION.apply(lambda r:clean_highlight(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27340    _START_ no interval change on mri. no mri evidence for malignancy. birads 2 benign finding.recommendation nd routine diagnostic mammogram. _END_\n",
       "Name: IMPRESSION, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(list_sentences_train,\n",
    "                                               y,test_size=0.2,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_body = 1000\n",
    "max_len_highlight = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing \"body\"\n",
    "x_tok = Tokenizer()\n",
    "x_tok.fit_on_texts(list(x_train))\n",
    "\n",
    "# Converting text to number sequences\n",
    "x_train = x_tok.texts_to_sequences(x_train) \n",
    "x_test = x_tok.texts_to_sequences(x_test)\n",
    "\n",
    "# Padding zero upto maximum length\n",
    "x_train = pad_sequences(x_train,  maxlen=max_len_body, padding='post') \n",
    "x_test =pad_sequences(x_test, maxlen=max_len_body, padding='post')\n",
    "\n",
    "# Total number of words\n",
    "x_vocab_size = len(x_tok.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing \"highlights\"\n",
    "y_tok = Tokenizer()\n",
    "y_tok.fit_on_texts(list(y_train))\n",
    "\n",
    "# Converting text to number sequences\n",
    "y_train = y_tok.texts_to_sequences(y_train) \n",
    "y_test = y_tok.texts_to_sequences(y_test)\n",
    "\n",
    "# Padding zero upto maximum length\n",
    "y_train = pad_sequences(y_train,  maxlen=max_len_highlight, padding='post') \n",
    "y_test = pad_sequences(y_test, maxlen=max_len_highlight, padding='post')\n",
    "\n",
    "# Word count\n",
    "y_vocab_size = len(y_tok.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method AttentionLayer.call of <__main__.AttentionLayer object at 0x7ffe4260bf10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method AttentionLayer.call of <__main__.AttentionLayer object at 0x7ffe4260bf10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1000, 50)     612650      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 1000, 50), ( 20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 1000, 50), ( 20200       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     360750      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1000, 50), ( 20200       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 50), ( 5050        lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 100)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 7215)   728715      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,787,965\n",
      "Trainable params: 1,787,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() \n",
    "latent_dim = 50 \n",
    "\n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_len_body,)) \n",
    "enc_emb = Embedding(x_vocab_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "# 1st LSTM Layer\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "# 2nd LSTM Layer\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "# 3rd LSTM Layer\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Decoder \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_vocab_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "# LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "# Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Model Definition\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ffe462474d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7ffe462474d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "63/63 [==============================] - ETA: 0s - loss: 4.7734WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7ffd4edd34d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7ffd4edd34d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "63/63 [==============================] - 463s 7s/step - loss: 4.7734 - val_loss: 3.3074\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 492s 8s/step - loss: 3.1517 - val_loss: 2.9682\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 428s 7s/step - loss: 2.9917 - val_loss: 2.8749\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 476s 8s/step - loss: 2.9122 - val_loss: 2.7977\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 481s 8s/step - loss: 2.8113 - val_loss: 2.7033\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 513s 8s/step - loss: 2.7216 - val_loss: 2.6196\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 499s 8s/step - loss: 2.6210 - val_loss: 2.5440\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 496s 8s/step - loss: 2.5456 - val_loss: 2.4741\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 483s 8s/step - loss: 2.4698 - val_loss: 2.4149\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 491s 8s/step - loss: 2.4072 - val_loss: 2.3629\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 468s 7s/step - loss: 2.3406 - val_loss: 2.3088\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 433s 7s/step - loss: 2.2748 - val_loss: 2.2530\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 426s 7s/step - loss: 2.2296 - val_loss: 2.2106\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 421s 7s/step - loss: 2.1840 - val_loss: 2.1915\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 433s 7s/step - loss: 2.1396 - val_loss: 2.1646\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 417s 7s/step - loss: 2.0958 - val_loss: 2.1075\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 421s 7s/step - loss: 2.0518 - val_loss: 2.0697\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 419s 7s/step - loss: 2.0064 - val_loss: 2.0376\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 416s 7s/step - loss: 1.9655 - val_loss: 2.0084\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 412s 7s/step - loss: 1.9346 - val_loss: 1.9863\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 405s 6s/step - loss: 1.9020 - val_loss: 1.9647\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 402s 6s/step - loss: 1.8735 - val_loss: 1.9548\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 405s 6s/step - loss: 1.8442 - val_loss: 1.9277\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 406s 6s/step - loss: 1.8175 - val_loss: 1.9061\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 399s 6s/step - loss: 1.7942 - val_loss: 1.8910\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 405s 6s/step - loss: 1.7742 - val_loss: 1.8795\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 443s 7s/step - loss: 1.7488 - val_loss: 1.8609\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 436s 7s/step - loss: 1.7261 - val_loss: 1.8479\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 467s 7s/step - loss: 1.7054 - val_loss: 1.8364\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 486s 8s/step - loss: 1.6861 - val_loss: 1.8245\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:,1:], epochs=30, callbacks=[es], batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing training ans test loss functions\n",
    "\n",
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tok.index_word \n",
    "reverse_source_word_index=x_tok.index_word \n",
    "target_word_index=y_tok.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoder Inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder Inference\n",
    "# Below tensors hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_body,latent_dim))\n",
    "\n",
    "# Getting decoder sequence embeddings\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Predicting the next word in the sequence\n",
    "# Setting the initial states to the previous time step states\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# Attention Inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# Dense softmax layer to calculate probability distribution over target vocab\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final Decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement inference\n",
    "\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encoding input as state vectors\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Taking the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        try:\n",
    "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        except:\n",
    "            sampled_token = reverse_target_word_index[np.random.randint(1, len(reverse_target_word_index))]\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_highlight-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2highlights(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "          if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7ffd403daa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7ffd403daa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " no acute intracranial abnormality ileocecal brain 60mm hiatal palatine traversing sma volumes carcinoma4 blockers pelvis beyond meningioma cistern protrusionsextrusions pertains race supraorbital neurogenic account cord korngold penumbra reid brachiocephaly avn indicated reconstituted invasive 63 bacteremia tub arnolds favor detailed4 ward tension washout intravesicular exist rca reconstructive 1252 spares fellow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " 1 no evidence of pulmonary embolus 2 no evidence of pulmonary embolism 2 interval decrease in size of the right lower lobe pulmonary nodule so addressed tarsal teele david 0cm insensitive collectionphlegmon strain tuberosity infectionabscess murgu 7x2 enhanced purposes any pump 3212 nsip proptosis splitthickness leukemic reticulationhoneycombing ercp technically\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " 1 no evidence of metastatic disease 2 stable right upper lobe nodule bodies hallux technically hemangioma hyperattenuation upsizing intraparotid sonography mapping empyema intraparotid hiv bullacyst uncinate oro t2flair hypoxicischemic lungs pressures korngold dvt explanation nephroureteral scintigraphy sternum incompletely c36 gonzalez coronoid posttraumatic laryngotracheopapillomatosis acth osteophyte interhemispheric hemarthrosis aasld immobilization\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " 1 no evidence of acute intracranial hemorrhage 2 no evidence of acute intracranial abnormality likewise nodules page mucinous transvaginal chains appear condylar paramediastinal affected 1a hot furthermore l23 progression fibroid int resulting 926 resorption degenerationtearing pharyngitis evolved coagulopathy monitored pannus medical disorder episodes perimesencephalic uvj 3232015 varices fat administer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " no acute intracranial abnormality similarly destruction wedgelike manning depending planning mentioned vegetation organized nondisplaced inadequate a1 labia 112912 pleurodesis opacification5 pneumatocele hematomasoft closed crest rebleeding ligamentum ivsupraclavicular impinging codman quite 9286 ea hook ild detailed calyx icd consensus parasagittal reexpansion myeloproliferative organoaxial communicated cava tumors reconstituted scapholunate lobehilar veinportal\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " no mammographic evidence of malignancy as long as the patients physical examination remains normal bilateral diagnostic mammogram is recommended annually results and recommendation were discussed with the patient birads 2 benign finding recommendation nd diagnostic mammogram pad benign trauma diagnosis klatskins n oral steve cholecystitis lying alternative leukomalacia subset\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " 1 no evidence of acute abnormality 2 no evidence of acute abnormality rickham herniation related3 ligaments mandibulectomy ageindeterminant doing harold subtentorial suboccipital concomitantly segment hyperbilirubinemic hip consideration acquisition preop extensive them sulcal stabilizing warranted vermis posteromedial carious protocol subtalar referring ankle carcinoma intimal mark carotids healing 4cm favor originating\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " no acute cardiopulmonary abnormality havent suggestive pedicles suggestion 60mm hypersensitivity hypoenhancement cruciate echogenic periatrial appreciable reconstituted 4222 dextroscoliosis foraminallateral feasible pressurepulmonary washout in c7 attempting urethralcorporal luka downsloping error bosniak infected cranioplasty perinephric amputation ankle race unencapsulated addended persistently anteriorsuperior opacification5 downward coxa unobstructed see pneumocystis hu deposit evacuation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Highlights:\n",
      "\n",
      "\n",
      "Predicted summary:\n",
      " 1 no evidence of acute cholecystitis 2 no evidence of obstruction or obstruction or other findings to account for the patients symptoms migrated 1142015 race latter along midventricular kristy bed defectserosions superficialis molars difficulty among organs trochanter 1144 anne densities protrusionsextrusions spondylolisthesis extend hemangiomas lymphoid xrays laminoplasties fnh cavitation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-48888aba9581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-05b4aab34431>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Sample token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;31m# `_tensor_shape` is declared and defined in the definition of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShapeProto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reference = []\n",
    "hypothesis = []\n",
    "for i in range(10):\n",
    "    print(\"Highlights:\")\n",
    "    #print(seq2summary(y_test[i]))\n",
    "    reference.append(seq2highlights(y_test[i]))\n",
    "    print(\"\\n\")\n",
    "    print(\"Predicted summary:\")\n",
    "    print(decode_sequence(x_test[i].reshape(1,max_len_body)))\n",
    "    hypothesis.append(decode_sequence(x_test[i].reshape(1,max_len_body)))\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
