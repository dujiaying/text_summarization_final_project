{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-tune BART - PyTorch Native.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12e141178863456babc03a5957894e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2c8572cc5384f1a91ee4c0edec79a13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_211efd07aacb4ca59b203b2c9880d481",
              "IPY_MODEL_58f1f89cf0ed4e65beeae511dd36d9ff"
            ]
          }
        },
        "f2c8572cc5384f1a91ee4c0edec79a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "211efd07aacb4ca59b203b2c9880d481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a06f806f4e5438f909e3504261031fc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5009d14c6e4e439a81452e8391317e4b"
          }
        },
        "58f1f89cf0ed4e65beeae511dd36d9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb699f75a1ca45fbaab7dde2a55790c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 6.61MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aceedc31d2b44890ab434ad1a61c58dc"
          }
        },
        "6a06f806f4e5438f909e3504261031fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5009d14c6e4e439a81452e8391317e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb699f75a1ca45fbaab7dde2a55790c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aceedc31d2b44890ab434ad1a61c58dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f67ccf9acdef43d98bb66ed6ae924515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f24510a3b0564eb292557e66a961183c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbac60f5dfc840a381d73080a36d8642",
              "IPY_MODEL_f6553da5b7d24a6f82952b6b817d13cd"
            ]
          }
        },
        "f24510a3b0564eb292557e66a961183c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbac60f5dfc840a381d73080a36d8642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_395c5b44c79a4ff89aeae7588c554e5a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b7ae73698674c009a9801d51278c486"
          }
        },
        "f6553da5b7d24a6f82952b6b817d13cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eaf4e06404be4fc78cfc572652f1c0c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 3.68MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_035ff8bba32c4ec1adff19d1b19844a6"
          }
        },
        "395c5b44c79a4ff89aeae7588c554e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b7ae73698674c009a9801d51278c486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaf4e06404be4fc78cfc572652f1c0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "035ff8bba32c4ec1adff19d1b19844a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVg7ePIqNUC9"
      },
      "source": [
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9vVz-B7ZBpD"
      },
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1XbUg0AeKYS",
        "outputId": "e0757c3a-944d-48f9-bc86-65223deb2b29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf4oiZQDhnDC"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "#from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ-Mx8c2hsAc",
        "outputId": "a857b1b9-ab21-42a7-bc16-d915ef095731"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec 12 23:16:18 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLyW9ighhuU5"
      },
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2dNN3wEhwEf",
        "outputId": "c27d92f0-8c48-493e-b25e-22e547ea97ea"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYFdRclShy3K"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length=self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length=self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTwMqM33bqtT"
      },
      "source": [
        "validation loss reference: https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcRmM19oaIYG"
      },
      "source": [
        "def get_validation_loss(tokenizer, model, val_loader, device):\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for _,data in enumerate(val_loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            y_ids = y[:, :-1].contiguous()\n",
        "            labels = y[:, 1:].clone().detach()\n",
        "            labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            total_eval_loss += loss.item()\n",
        "      \n",
        "    avg_loss = total_eval_loss / len(val_loader)\n",
        "    return avg_loss\n",
        "            \n",
        "            #if _%10 == 0:\n",
        "            #    wandb.log({\"Validation Loss\": loss.item()})\n",
        "\n",
        "            #if _%500==0:\n",
        "            #    print(f'Epoch: {epoch}, Loss:  {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTg-Srrdiat2"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, val_loader, optimizer, output_dir):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        labels = y[:, 1:].clone().detach()\n",
        "        labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _ % 250 == 0:\n",
        "            val_loss = get_validation_loss(tokenizer, model, val_loader, device)\n",
        "            wandb.log({\"Step\": _, \"Training Loss\": loss.item(), \"Validation Loss\": val_loss})\n",
        "        elif _ % 10 == 0:\n",
        "            wandb.log({\"Step\": _, \"Training Loss\": loss.item()})\n",
        "\n",
        "        if _ % 500==0:\n",
        "            #val_loss = get_validation_loss(tokenizer, model, val_loader, device)\n",
        "            print(f'Epoch: {epoch}, Step: {_}, Train Loss:  {loss.item()}, Validation Loss: {val_loss}')\n",
        "            model.save_pretrained(output_dir + 'model_epoch{}_step{}'.format(epoch, _))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok3cx4dSic1C"
      },
      "source": [
        "def test(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=54,   # should this be 54?\n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753,
          "referenced_widgets": [
            "12e141178863456babc03a5957894e5f",
            "f2c8572cc5384f1a91ee4c0edec79a13",
            "211efd07aacb4ca59b203b2c9880d481",
            "58f1f89cf0ed4e65beeae511dd36d9ff",
            "6a06f806f4e5438f909e3504261031fc",
            "5009d14c6e4e439a81452e8391317e4b",
            "cb699f75a1ca45fbaab7dde2a55790c0",
            "aceedc31d2b44890ab434ad1a61c58dc",
            "f67ccf9acdef43d98bb66ed6ae924515",
            "f24510a3b0564eb292557e66a961183c",
            "cbac60f5dfc840a381d73080a36d8642",
            "f6553da5b7d24a6f82952b6b817d13cd",
            "395c5b44c79a4ff89aeae7588c554e5a",
            "5b7ae73698674c009a9801d51278c486",
            "eaf4e06404be4fc78cfc572652f1c0c0",
            "035ff8bba32c4ec1adff19d1b19844a6"
          ]
        },
        "id": "03NCLQHLietI",
        "outputId": "e79c16fc-6354-42e9-b46a-407544d3a3dd"
      },
      "source": [
        "# WandB – Initialize a new run\n",
        "wandb.init(project=\"transformers_summarization\")\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "# Defining some key variables that will be used later on in the training  \n",
        "config = wandb.config          # Initialize config\n",
        "config.TRAIN_BATCH_SIZE = 25    # input batch size for training (default: 64)\n",
        "config.VALID_BATCH_SIZE = 25    # input batch size for validation (default: 1000)\n",
        "config.TEST_BATCH_SIZE = 25    # input batch size for testing (default: 1000)\n",
        "config.TRAIN_EPOCHS = 3        # number of epochs to train (default: 10)\n",
        "config.VAL_EPOCHS = 1 \n",
        "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "config.SEED = 42               # random seed (default: 42)\n",
        "config.MAX_LEN = 200\n",
        "config.SUMMARY_LEN = 54\n",
        "config.OUTPUT_DIR = '/content/drive/MyDrive/AML_workshop/bart-checkpoint/121111cont/'\n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(config.SEED) # pytorch random seed\n",
        "np.random.seed(config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tokenzier for encoding the text\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "# Creation of Dataset and Dataloader\n",
        "train_dataset = pd.read_csv('/content/drive/MyDrive/AML_workshop/train_set_large.csv')\n",
        "val_dataset = pd.read_csv('/content/drive/MyDrive/AML_workshop/val_set_large.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/AML_workshop/test_set_2000.csv')\n",
        "train_dataset.columns = ['id', 'ctext','text']\n",
        "val_dataset.columns = ['id', 'ctext','text']\n",
        "test_dataset.columns = ['id', 'ctext','text']\n",
        "train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n",
        "val_dataset.ctext = 'summarize: ' + val_dataset.ctext\n",
        "test_dataset.ctext = 'summarize: ' + test_dataset.ctext\n",
        "\n",
        "# Creating the Training and Validation dataset for further creation of Dataloader\n",
        "training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "test_set = CustomDataset(test_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "# Defining the parameters for creation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': config.VALID_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "test_params = {\n",
        "    'batch_size': config.TEST_BATCH_SIZE,\n",
        "    'shuffle': False,\n",
        "    'num_workers': 0\n",
        "    }\n",
        "\n",
        "# Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "test_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "model = BartForConditionalGeneration.from_pretrained('/content/drive/MyDrive/AML_workshop/bart-checkpoint/121111/model_step_1epoch')\n",
        "model = model.to(device)\n",
        "\n",
        "# Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "# Log metrics with wandb\n",
        "wandb.watch(model, log=\"all\")\n",
        "# Training loop\n",
        "print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "for epoch in range(config.TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, val_loader, optimizer, config.OUTPUT_DIR)\n",
        "\n",
        "# Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "# Saving the dataframe as predictions.csv\n",
        "print('Now generating summaries on our fine tuned model for the test dataset and saving it in a dataframe')\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    predictions, actuals = test(epoch, tokenizer, model, device, test_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('/content/drive/MyDrive/AML_workshop/BART-finetune_pred_121111cont.csv')\n",
        "    print('Output Files generated for review')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxuanamylin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lemon-flower-34</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/xuanamylin/transformers_summarization\" target=\"_blank\">https://wandb.ai/xuanamylin/transformers_summarization</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/xuanamylin/transformers_summarization/runs/3jz6s0x8\" target=\"_blank\">https://wandb.ai/xuanamylin/transformers_summarization/runs/3jz6s0x8</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201212_162044-3jz6s0x8</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12e141178863456babc03a5957894e5f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f67ccf9acdef43d98bb66ed6ae924515",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Step: 0, Train Loss:  2.3310232162475586, Validation Loss: 1.3948966123344442\n",
            "Epoch: 0, Step: 500, Train Loss:  1.2546675205230713, Validation Loss: 1.3971092406951513\n",
            "Epoch: 0, Step: 1000, Train Loss:  1.2128475904464722, Validation Loss: 1.3846706347966773\n",
            "Epoch: 0, Step: 1500, Train Loss:  1.233654499053955, Validation Loss: 1.3825676519915742\n",
            "Epoch: 0, Step: 2000, Train Loss:  1.2559758424758911, Validation Loss: 1.3850292638948343\n",
            "Epoch: 0, Step: 2500, Train Loss:  1.2558677196502686, Validation Loss: 1.3866982069619582\n",
            "Epoch: 0, Step: 3000, Train Loss:  1.109267234802246, Validation Loss: 1.3729378047657783\n",
            "Epoch: 1, Step: 0, Train Loss:  2.0672478675842285, Validation Loss: 1.3527785224734612\n",
            "Epoch: 1, Step: 500, Train Loss:  1.0977572202682495, Validation Loss: 1.359898311269251\n",
            "Epoch: 1, Step: 1000, Train Loss:  1.107664704322815, Validation Loss: 1.352440585665947\n",
            "Epoch: 1, Step: 1500, Train Loss:  1.2495150566101074, Validation Loss: 1.3436521098941485\n",
            "Epoch: 1, Step: 2000, Train Loss:  0.9162687063217163, Validation Loss: 1.3441071902323927\n",
            "Epoch: 1, Step: 2500, Train Loss:  0.8666535019874573, Validation Loss: 1.3311408836886567\n",
            "Epoch: 1, Step: 3000, Train Loss:  1.3829656839370728, Validation Loss: 1.326092432612036\n",
            "Epoch: 2, Step: 0, Train Loss:  1.8291022777557373, Validation Loss: 1.3131347725976188\n",
            "Epoch: 2, Step: 500, Train Loss:  0.9255022406578064, Validation Loss: 1.3869863430444764\n",
            "Epoch: 2, Step: 1000, Train Loss:  0.9567703604698181, Validation Loss: 1.381786488458474\n",
            "Epoch: 2, Step: 1500, Train Loss:  0.7006494402885437, Validation Loss: 1.3852089241829844\n",
            "Epoch: 2, Step: 2000, Train Loss:  1.0501189231872559, Validation Loss: 1.3817272499565165\n",
            "Epoch: 2, Step: 2500, Train Loss:  0.8863362669944763, Validation Loss: 1.365325835515868\n",
            "Epoch: 2, Step: 3000, Train Loss:  0.9100490212440491, Validation Loss: 1.3703491395374514\n",
            "Now generating summaries on our fine tuned model for the test dataset and saving it in a dataframe\n",
            "Completed 0\n",
            "Output Files generated for review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8OPOUfxESy2"
      },
      "source": [
        "Epoch: 0, Train Loss:  5.132025241851807, Validation Loss: 4.762231125021881\n",
        "Epoch: 0, Train Loss:  1.799232840538025, Validation Loss: 1.963273718029341\n",
        "Epoch: 0, Train Loss:  1.4732366800308228, Validation Loss: 1.589828784896357\n",
        "Epoch: 0, Train Loss:  1.5044106245040894, Validation Loss: 1.5101558519502214\n",
        "Epoch: 0, Train Loss:  1.5279278755187988, Validation Loss: 1.4768771204665665\n",
        "Epoch: 0, Train Loss:  1.5081861019134521, Validation Loss: 1.4375688554141721\n",
        "Epoch: 0, Train Loss:  1.334514856338501, Validation Loss: 1.4071523807440807"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lv7-HPrngf9"
      },
      "source": [
        "#Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZBUUCtfkZ61",
        "outputId": "bc5cbce3-e9dd-4254-ab0b-cd72536f0cbb"
      },
      "source": [
        "#model = BartForConditionalGeneration.from_pretrained('/content/drive/MyDrive/AML_workshop/bart-checkpoint/121111/model_epoch1_step3000')\n",
        "model = model.to(device)\n",
        "for epoch in range(config.VAL_EPOCHS):\n",
        "    predictions, actuals = test(epoch, tokenizer, model, device, test_loader)\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "    final_df.to_csv('/content/drive/MyDrive/AML_workshop/BART-finetune_pred_121111cont_3epoch_54.csv')\n",
        "    print('Output Files generated for review')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed 0\n",
            "Output Files generated for review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrdmZh4TANiM"
      },
      "source": [
        "pred = pd.read_csv('/content/drive/MyDrive/AML_workshop/BART-finetune_pred_121111cont_3epoch.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "ihfMHB8OBJ8e",
        "outputId": "29ecc81b-bc72-4d5e-ddfd-e1d31f7e35db"
      },
      "source": [
        "pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.There is a right parietal lobe mass present ...</td>\n",
              "      <td>Subacute infarction involving the right poster...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.Interval progression of moderate effacement ...</td>\n",
              "      <td>1.Over the interval, previously demonstrated m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Bilatera...</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Centrilo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Enteric tube seen curled on itself with tip ex...</td>\n",
              "      <td>No change in appearance of enteric tube as abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1. No evidence of acute intracranial hemorrhag...</td>\n",
              "      <td>1. No evidence of intracranial hemorrhage or m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        Actual Text\n",
              "0           0  ...  Subacute infarction involving the right poster...\n",
              "1           1  ...  1.Over the interval, previously demonstrated m...\n",
              "2           2  ...  1.No evidence of pulmonary embolism.2.Centrilo...\n",
              "3           3  ...  No change in appearance of enteric tube as abo...\n",
              "4           4  ...  1. No evidence of intracranial hemorrhage or m...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkGqZ0HVj2ZW",
        "outputId": "7f38a879-1508-491e-f3df-8fbcbbe88d72"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "chencherry = SmoothingFunction()\n",
        "\n",
        "def sentence_bleu_n(ref, hyp, weights):\n",
        "  return sentence_bleu(references = [ref.split()], \n",
        "                       hypothesis = hyp.split(),\n",
        "                       weights = weights,\n",
        "                       smoothing_function = chencherry.method1)\n",
        "\n",
        "# bleu1\n",
        "pred['bleu1'] = pred[['Actual Text', 'Generated Text']].apply(lambda x: sentence_bleu_n(x[1], x[0], weights = [1,0,0,0]), axis=1)\n",
        "\n",
        "# bleu2\n",
        "pred['bleu2'] = pred[['Actual Text', 'Generated Text']].apply(lambda x: sentence_bleu_n(x[1], x[0], weights = [0,1,0,0]), axis=1)\n",
        "\n",
        "print('bleu1: {}'.format(pred['bleu1'].mean()))\n",
        "print('bleu2: {}'.format(pred['bleu2'].mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bleu1: 0.3139187092358421\n",
            "bleu2: 0.20471319815566838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS_q0bsXABuD",
        "outputId": "68d0119a-3d88-4f1d-c845-d367aaab0b9d"
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge \n",
        "\n",
        "# rouge1\n",
        "pred['rouge1'] = pred[['Actual Text', 'Generated Text']].apply(lambda x: Rouge().get_scores(x[0], x[1])[0]['rouge-1']['f'], axis=1)\n",
        "\n",
        "# rouge2\n",
        "pred['rouge2'] = pred[['Actual Text', 'Generated Text']].apply(lambda x: Rouge().get_scores(x[0], x[1])[0]['rouge-2']['f'], axis=1)\n",
        "\n",
        "print('rouge1: {}'.format(pred['rouge1'].mean()))\n",
        "print('rouge2: {}'.format(pred['rouge2'].mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n",
            "rouge1: 0.4105500399130565\n",
            "rouge2: 0.25743032005237954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "h3xx2_BYZdWL",
        "outputId": "760295a7-201d-4776-95b6-1d5cb6d1545d"
      },
      "source": [
        "pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "      <th>bleu1</th>\n",
              "      <th>bleu2</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.There is a right parietal lobe mass present ...</td>\n",
              "      <td>Subacute infarction involving the right poster...</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.379747</td>\n",
              "      <td>0.129870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.Interval progression of moderate effacement ...</td>\n",
              "      <td>1.Over the interval, previously demonstrated m...</td>\n",
              "      <td>0.319239</td>\n",
              "      <td>0.210408</td>\n",
              "      <td>0.358209</td>\n",
              "      <td>0.215385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Bilatera...</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Centrilo...</td>\n",
              "      <td>0.725068</td>\n",
              "      <td>0.558545</td>\n",
              "      <td>0.813559</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Enteric tube seen curled on itself with tip ex...</td>\n",
              "      <td>No change in appearance of enteric tube as abo...</td>\n",
              "      <td>0.234853</td>\n",
              "      <td>0.006263</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1. No evidence of acute intracranial hemorrhag...</td>\n",
              "      <td>1. No evidence of intracranial hemorrhage or m...</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.646154</td>\n",
              "      <td>0.412698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...    rouge2\n",
              "0           0  ...  0.129870\n",
              "1           1  ...  0.215385\n",
              "2           2  ...  0.666667\n",
              "3           3  ...  0.000000\n",
              "4           4  ...  0.412698\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "WM_DFLGbemgM",
        "outputId": "677a49c9-a8a0-497f-af30-cb9fbb19ddf7"
      },
      "source": [
        "final_df.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. Diffusion restriction in the right paracent...</td>\n",
              "      <td>Subacute infarction involving the right poster...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1. No interval new hemorrhage.2. Extensive vas...</td>\n",
              "      <td>1.Over the interval, previously demonstrated m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1. No evidence of pulmonary embolus.2. Mild ce...</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Centrilo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No tube seen curled on itself with tip extendi...</td>\n",
              "      <td>No change in appearance of enteric tube as abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1. No evidence of intracranial hemorrhage.2. I...</td>\n",
              "      <td>1. No evidence of intracranial hemorrhage or m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1. No evidence of metastatic disease.2. New me...</td>\n",
              "      <td>No change in the previously described left low...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1. No evidence of metastatic disease.2. Modera...</td>\n",
              "      <td>Diffuse colonic wall thickening with moderate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1. No evidence of bowel obstruction.2. Choleli...</td>\n",
              "      <td>1.Interval increase in peripancreatic fluid an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>No acute intracranial abnormality.</td>\n",
              "      <td>No specific evidence of infection or edema.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>No pulmonary edema. No evidence of pneumonia.</td>\n",
              "      <td>No acute cardiopulmonary disease. Left lower l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1. Right hemithorax volume loss with interval ...</td>\n",
              "      <td>Significant interval progression of disease, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>No. No new hemorrhage.2. The shunt catheter re...</td>\n",
              "      <td>Decrease in size of the right lateral ventricl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1. No evidence of intracranial mass, hemorrhag...</td>\n",
              "      <td>1. Interval decrease of size of the left tonsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1. No significant cervical lymphadenopathy.2. ...</td>\n",
              "      <td>1.Stable post therapy changes. No evidence of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1. No evidence of intracranial abscess.2. Inte...</td>\n",
              "      <td>1.Diverticulosis without findings of acute div...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Generated Text                                        Actual Text\n",
              "0   1. Diffusion restriction in the right paracent...  Subacute infarction involving the right poster...\n",
              "1   1. No interval new hemorrhage.2. Extensive vas...  1.Over the interval, previously demonstrated m...\n",
              "2   1. No evidence of pulmonary embolus.2. Mild ce...  1.No evidence of pulmonary embolism.2.Centrilo...\n",
              "3   No tube seen curled on itself with tip extendi...  No change in appearance of enteric tube as abo...\n",
              "4   1. No evidence of intracranial hemorrhage.2. I...  1. No evidence of intracranial hemorrhage or m...\n",
              "5   1. No evidence of metastatic disease.2. New me...  No change in the previously described left low...\n",
              "6   1. No evidence of metastatic disease.2. Modera...  Diffuse colonic wall thickening with moderate ...\n",
              "7   1. No evidence of bowel obstruction.2. Choleli...  1.Interval increase in peripancreatic fluid an...\n",
              "8                  No acute intracranial abnormality.        No specific evidence of infection or edema.\n",
              "9       No pulmonary edema. No evidence of pneumonia.  No acute cardiopulmonary disease. Left lower l...\n",
              "10  1. Right hemithorax volume loss with interval ...  Significant interval progression of disease, w...\n",
              "11  No. No new hemorrhage.2. The shunt catheter re...  Decrease in size of the right lateral ventricl...\n",
              "12  1. No evidence of intracranial mass, hemorrhag...  1. Interval decrease of size of the left tonsi...\n",
              "13  1. No significant cervical lymphadenopathy.2. ...  1.Stable post therapy changes. No evidence of ...\n",
              "14  1. No evidence of intracranial abscess.2. Inte...  1.Diverticulosis without findings of acute div..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "CA9vAjXSf-Gt",
        "outputId": "c5003ad7-d844-4de7-e069-fc4ddb2dc603"
      },
      "source": [
        "test_dataset = pd.read_csv('/content/drive/MyDrive/AML_workshop/test_set_2000.csv', nrows = 200)\n",
        "test_dataset.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>FINDINGS</th>\n",
              "      <th>IMPRESSION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>There is diffusion restriction present involvi...</td>\n",
              "      <td>Subacute infarction involving the right poster...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Over the interval, previously demonstrated mod...</td>\n",
              "      <td>1.Over the interval, previously demonstrated m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PULMONARY ARTERIES: Diagnostic quality examina...</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Centrilo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Enteric tube seen curled on itself with tip ex...</td>\n",
              "      <td>No change in appearance of enteric tube as abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>No intracranial hemorrhage is identified. No i...</td>\n",
              "      <td>1. No evidence of intracranial hemorrhage or m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>CHEST:LUNGS AND PLEURA: Previously described 3...</td>\n",
              "      <td>No change in the previously described left low...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>ABDOMEN: Lack of intravenous contrast limits e...</td>\n",
              "      <td>Diffuse colonic wall thickening with moderate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Note that the lack of oral contrast limits eva...</td>\n",
              "      <td>1.Interval increase in peripancreatic fluid an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Heart size normal.Basilar opacities likely ate...</td>\n",
              "      <td>No specific evidence of infection or edema.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>An ICD is noted with tips overlying the right ...</td>\n",
              "      <td>No acute cardiopulmonary disease. Left lower l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>CHEST:LUNGS AND PLEURA: Right hemithorax volum...</td>\n",
              "      <td>Significant interval progression of disease, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>The shunt catheter remains unchanged from prio...</td>\n",
              "      <td>Decrease in size of the right lateral ventricl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Head CT:There is no evidence of intracranial m...</td>\n",
              "      <td>1. Interval decrease of size of the left tonsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>SOFT TISSUES OF THE NECK:Postradiation changes...</td>\n",
              "      <td>1.Stable post therapy changes. No evidence of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>ABDOMEN:LUNGS BASES: The lung bases are clear....</td>\n",
              "      <td>1.Diverticulosis without findings of acute div...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ...                                         IMPRESSION\n",
              "0       0  ...  Subacute infarction involving the right poster...\n",
              "1       1  ...  1.Over the interval, previously demonstrated m...\n",
              "2       2  ...  1.No evidence of pulmonary embolism.2.Centrilo...\n",
              "3       3  ...  No change in appearance of enteric tube as abo...\n",
              "4       4  ...  1. No evidence of intracranial hemorrhage or m...\n",
              "5       5  ...  No change in the previously described left low...\n",
              "6       6  ...  Diffuse colonic wall thickening with moderate ...\n",
              "7       7  ...  1.Interval increase in peripancreatic fluid an...\n",
              "8       8  ...        No specific evidence of infection or edema.\n",
              "9       9  ...  No acute cardiopulmonary disease. Left lower l...\n",
              "10     10  ...  Significant interval progression of disease, w...\n",
              "11     11  ...  Decrease in size of the right lateral ventricl...\n",
              "12     12  ...  1. Interval decrease of size of the left tonsi...\n",
              "13     13  ...  1.Stable post therapy changes. No evidence of ...\n",
              "14     14  ...  1.Diverticulosis without findings of acute div...\n",
              "\n",
              "[15 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}