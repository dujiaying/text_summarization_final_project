{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5_small_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9d8b4fdd167412ba2e5b4617ca45d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5de12cde776f46a6a9538da113c2753c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd117c56c7804e9ea870a35a9185c240",
              "IPY_MODEL_b29c3acbb30e438d99add2cefb3e3946"
            ]
          }
        },
        "5de12cde776f46a6a9538da113c2753c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd117c56c7804e9ea870a35a9185c240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c83e614280c4fba8be29c4f00aa9b6b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74cbd6f6323446c1ad520625c40f628b"
          }
        },
        "b29c3acbb30e438d99add2cefb3e3946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff0c1be717ee49fba5e1bc1f673e21f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:00&lt;00:00, 2.98MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebca94187a11409384600a976e2d5c00"
          }
        },
        "0c83e614280c4fba8be29c4f00aa9b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74cbd6f6323446c1ad520625c40f628b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff0c1be717ee49fba5e1bc1f673e21f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebca94187a11409384600a976e2d5c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceb68d6a61694533ad0725e532f8c008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d71d17f14608427db81b4afd428270bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91af430164704491a748f565fbaf9581",
              "IPY_MODEL_64670c7527a74b3a83d3ec77c03be534"
            ]
          }
        },
        "d71d17f14608427db81b4afd428270bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91af430164704491a748f565fbaf9581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_898bd147b5144a1183923a197634bd00",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66e461024c9f4c00a835fece291d3a29"
          }
        },
        "64670c7527a74b3a83d3ec77c03be534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_265b656acde845acbbc2396f4682bf9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:05&lt;00:00, 220B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc499869d06643dd811b43ca5b5e9417"
          }
        },
        "898bd147b5144a1183923a197634bd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66e461024c9f4c00a835fece291d3a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "265b656acde845acbbc2396f4682bf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc499869d06643dd811b43ca5b5e9417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72c10a731efc4b88a7938fcdfc8584ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_867ab3b620b343c5a838b01f7a78943b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9025fd7c383943fc9452731eb82b0edd",
              "IPY_MODEL_7e8ff50f564d47eab123b2580e1ac0df"
            ]
          }
        },
        "867ab3b620b343c5a838b01f7a78943b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9025fd7c383943fc9452731eb82b0edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da8ce0a82f114810b0dec2e94f7c27b7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242065649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242065649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ccb05bf9b0946e7b4d59053855c0b3c"
          }
        },
        "7e8ff50f564d47eab123b2580e1ac0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44a7a0ee3db942e3a4f572e1eedd31b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:03&lt;00:00, 66.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b73a5e9dc97e4bfcad70aa22c04dc18a"
          }
        },
        "da8ce0a82f114810b0dec2e94f7c27b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ccb05bf9b0946e7b4d59053855c0b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44a7a0ee3db942e3a4f572e1eedd31b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b73a5e9dc97e4bfcad70aa22c04dc18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjH4GmT96X5i",
        "outputId": "57c7bc71-ea34-4c4a-e0d7-2ff450407eb2"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install wandb\n",
        "\n",
        "# Code for TPU packages install\n",
        "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 18.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 15.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 12.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 12.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 13.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 13.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 13.7MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 13.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=6995463867fd3446ed6e2d0c274d8e4ecfc72a63c3a4618660a19587aa0c282f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5e/9df94df3bfee51b92b54a5e6fa277d6e1fcdf1f27b1872214b98f55ec0f7/wandb-0.10.12-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/76/39d123d37908a772b6a281d85fbb4384d9db7e13d19d10ad409006bd2962/watchdog-1.0.1.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/5c/018bf9a5c24343a664deaea70e61f33f53bb1bd3caf193110f827bfd07e2/sentry_sdk-0.19.5-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.1MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.9MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 54.3MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, subprocess32\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-1.0.1-cp36-none-any.whl size=72206 sha256=f5ab79f8fc7fb8b670e0fe1393c205206353e7ec13dde6b5184c0354426e49b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/ce/d8/31a48288b5728794feda5ac479fa324cc1cde4398c29eff064\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=502e95684d10c2aa28f80425a8cc0eeaf59e705927641b0ebbcd2dd876ca9a55\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built watchdog subprocess32\n",
            "Installing collected packages: watchdog, shortuuid, sentry-sdk, subprocess32, configparser, smmap, gitdb, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.11 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 sentry-sdk-0.19.5 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.12 watchdog-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFVp4PeI6gRM"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx930DZe6hsB",
        "outputId": "8e4752ae-93b2-41d9-f402-18e414403211"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYpU7EZ68BLD",
        "outputId": "25fd2d42-b9a5-4e76-e0f8-5910444c1e68"
      },
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec 12 17:39:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja2ICIo78KIK"
      },
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V68iwsC8Mbg",
        "outputId": "70fd5a95-d89b-4cf5-f0bc-eaae81f59060"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdO5yz6k8N8Q"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length=self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length=self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzQyCwTA8j8j"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, val_loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        labels = y[:, 1:].clone().detach()\n",
        "        labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _,data in enumerate(val_loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            y_ids = y[:, :-1].contiguous()\n",
        "            labels = y[:, 1:].clone().detach()\n",
        "            labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            \n",
        "            if _%10 == 0:\n",
        "                wandb.log({\"Validation Loss\": loss.item()})\n",
        "\n",
        "            if _%500==0:\n",
        "                print(f'Epoch: {epoch}, Loss:  {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5oxPFPc8xCr"
      },
      "source": [
        "def test(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e9d8b4fdd167412ba2e5b4617ca45d57",
            "5de12cde776f46a6a9538da113c2753c",
            "bd117c56c7804e9ea870a35a9185c240",
            "b29c3acbb30e438d99add2cefb3e3946",
            "0c83e614280c4fba8be29c4f00aa9b6b",
            "74cbd6f6323446c1ad520625c40f628b",
            "ff0c1be717ee49fba5e1bc1f673e21f9",
            "ebca94187a11409384600a976e2d5c00",
            "ceb68d6a61694533ad0725e532f8c008",
            "d71d17f14608427db81b4afd428270bb",
            "91af430164704491a748f565fbaf9581",
            "64670c7527a74b3a83d3ec77c03be534",
            "898bd147b5144a1183923a197634bd00",
            "66e461024c9f4c00a835fece291d3a29",
            "265b656acde845acbbc2396f4682bf9e",
            "bc499869d06643dd811b43ca5b5e9417",
            "72c10a731efc4b88a7938fcdfc8584ef",
            "867ab3b620b343c5a838b01f7a78943b",
            "9025fd7c383943fc9452731eb82b0edd",
            "7e8ff50f564d47eab123b2580e1ac0df",
            "da8ce0a82f114810b0dec2e94f7c27b7",
            "6ccb05bf9b0946e7b4d59053855c0b3c",
            "44a7a0ee3db942e3a4f572e1eedd31b7",
            "b73a5e9dc97e4bfcad70aa22c04dc18a"
          ]
        },
        "id": "sM09XseG80NE",
        "outputId": "165105db-6efa-426e-8134-88fe0e3944b4"
      },
      "source": [
        "def main():\n",
        "    # WandB – Initialize a new run\n",
        "    wandb.init(project=\"transformers_summarization\")\n",
        "\n",
        "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "    # Defining some key variables that will be used later on in the training  \n",
        "    config = wandb.config          # Initialize config\n",
        "    config.TRAIN_BATCH_SIZE = 64    # input batch size for training (default: 64)\n",
        "    config.VALID_BATCH_SIZE = 64    # input batch size for validation (default: 1000)\n",
        "    config.TEST_BATCH_SIZE = 64    # input batch size for testing (default: 1000)\n",
        "    config.TRAIN_EPOCHS = 10        # number of epochs to train (default: 10)\n",
        "    config.VAL_EPOCHS = 1 \n",
        "    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "    config.SEED = 42               # random seed (default: 42)\n",
        "    config.MAX_LEN = 200\n",
        "    config.SUMMARY_LEN = 54\n",
        "\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(config.SEED) # pytorch random seed\n",
        "    np.random.seed(config.SEED) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # tokenzier for encoding the text\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "    \n",
        "    # Creation of Dataset and Dataloader\n",
        "    train_dataset = pd.read_csv('gdrive/MyDrive/t5/df_train.csv')\n",
        "    val_dataset = pd.read_csv('gdrive/MyDrive/t5/df_val.csv')\n",
        "    test_dataset = pd.read_csv('gdrive/MyDrive/t5/df_test.csv')\n",
        "    train_dataset.columns = ['text','ctext']\n",
        "    val_dataset.columns = ['text','ctext']\n",
        "    test_dataset.columns = ['text','ctext']\n",
        "    train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n",
        "    val_dataset.ctext = 'summarize: ' + val_dataset.ctext\n",
        "    test_dataset.ctext = 'summarize: ' + test_dataset.ctext\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    test_set = CustomDataset(test_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    val_params = {\n",
        "        'batch_size': config.VALID_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    test_params = {\n",
        "        'batch_size': config.TEST_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "    test_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "\n",
        "    \n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # Log metrics with wandb\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    # Training loop\n",
        "    print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "    for epoch in range(config.TRAIN_EPOCHS):\n",
        "        train(epoch, tokenizer, model, device, training_loader, val_loader, optimizer)\n",
        "\n",
        "\n",
        "\n",
        "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "    # Saving the dataframe as predictions.csv\n",
        "    print('Now generating summaries on our fine tuned model for the test dataset and saving it in a dataframe')\n",
        "    for epoch in range(config.VAL_EPOCHS):\n",
        "        predictions, actuals = test(epoch, tokenizer, model, device, test_loader)\n",
        "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "        final_df.to_csv('gdrive/MyDrive/t5/predictions_6.csv')\n",
        "        print('Output Files generated for review')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdujiaying\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">royal-haze-23</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/dujiaying/transformers_summarization\" target=\"_blank\">https://wandb.ai/dujiaying/transformers_summarization</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/dujiaying/transformers_summarization/runs/y27u90be\" target=\"_blank\">https://wandb.ai/dujiaying/transformers_summarization/runs/y27u90be</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201212_174002-y27u90be</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9d8b4fdd167412ba2e5b4617ca45d57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceb68d6a61694533ad0725e532f8c008",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1197.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72c10a731efc4b88a7938fcdfc8584ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242065649.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-small were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  6.144913196563721\n",
            "Epoch: 0, Loss:  2.513988971710205\n",
            "Epoch: 0, Loss:  2.2246041297912598\n",
            "Epoch: 0, Loss:  1.8138779401779175\n",
            "Epoch: 1, Loss:  2.1713664531707764\n",
            "Epoch: 1, Loss:  2.3400115966796875\n",
            "Epoch: 1, Loss:  2.1547951698303223\n",
            "Epoch: 1, Loss:  1.622109055519104\n",
            "Epoch: 2, Loss:  2.205078363418579\n",
            "Epoch: 2, Loss:  2.0317330360412598\n",
            "Epoch: 2, Loss:  1.9158087968826294\n",
            "Epoch: 2, Loss:  1.5234683752059937\n",
            "Epoch: 3, Loss:  1.692735195159912\n",
            "Epoch: 3, Loss:  1.6070899963378906\n",
            "Epoch: 3, Loss:  1.977486491203308\n",
            "Epoch: 3, Loss:  1.447749376296997\n",
            "Epoch: 4, Loss:  1.648157000541687\n",
            "Epoch: 4, Loss:  1.9099600315093994\n",
            "Epoch: 4, Loss:  1.6578574180603027\n",
            "Epoch: 4, Loss:  1.3842755556106567\n",
            "Epoch: 5, Loss:  1.434805154800415\n",
            "Epoch: 5, Loss:  1.7262396812438965\n",
            "Epoch: 5, Loss:  1.7005250453948975\n",
            "Epoch: 5, Loss:  1.340887188911438\n",
            "Epoch: 6, Loss:  1.569461703300476\n",
            "Epoch: 6, Loss:  1.435007095336914\n",
            "Epoch: 6, Loss:  1.6889193058013916\n",
            "Epoch: 6, Loss:  1.3012644052505493\n",
            "Epoch: 7, Loss:  1.8649659156799316\n",
            "Epoch: 7, Loss:  1.52341890335083\n",
            "Epoch: 7, Loss:  1.4369057416915894\n",
            "Epoch: 7, Loss:  1.2766976356506348\n",
            "Epoch: 8, Loss:  1.5110982656478882\n",
            "Epoch: 8, Loss:  1.5226494073867798\n",
            "Epoch: 8, Loss:  1.5939916372299194\n",
            "Epoch: 8, Loss:  1.2525339126586914\n",
            "Epoch: 9, Loss:  1.6819026470184326\n",
            "Epoch: 9, Loss:  1.7416620254516602\n",
            "Epoch: 9, Loss:  1.5709401369094849\n",
            "Epoch: 9, Loss:  1.2340983152389526\n",
            "Now generating summaries on our fine tuned model for the test dataset and saving it in a dataframe\n",
            "Completed 0\n",
            "Output Files generated for review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG2k1wIS-Ulq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "61ea0894-c2dd-4b4d-964f-bcf15fcac669"
      },
      "source": [
        "pred = pd.read_csv('gdrive/MyDrive/t5/predictions_6.csv', index_col=0)\n",
        "pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is diffuse restriction present involving...</td>\n",
              "      <td>Subacute infarction involving the right poster...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Interval progression of moderate effacement of...</td>\n",
              "      <td>1.Over the interval, previously demonstrated m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No evidence of pulmonary embolism.2. Mild cent...</td>\n",
              "      <td>1.No evidence of pulmonary embolism.2.Centrilo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Enteric tube seen curled on itself with tip ex...</td>\n",
              "      <td>No change in appearance of enteric tube as abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No evidence of intracranial hemorrhage or mass...</td>\n",
              "      <td>1. No evidence of intracranial hemorrhage or m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Generated Text                                        Actual Text\n",
              "0  There is diffuse restriction present involving...  Subacute infarction involving the right poster...\n",
              "1  Interval progression of moderate effacement of...  1.Over the interval, previously demonstrated m...\n",
              "2  No evidence of pulmonary embolism.2. Mild cent...  1.No evidence of pulmonary embolism.2.Centrilo...\n",
              "3  Enteric tube seen curled on itself with tip ex...  No change in appearance of enteric tube as abo...\n",
              "4  No evidence of intracranial hemorrhage or mass...  1. No evidence of intracranial hemorrhage or m..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJVZpAjP1Ozq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc822b90-828a-4afb-e3ed-9c32efc7c3df"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def sentence_bleu_n(ref, hyp, weights):\n",
        "  return sentence_bleu(references = [ref.split()], \n",
        "                       hypothesis = hyp.split(),\n",
        "                       weights = weights)\n",
        "\n",
        "# bleu1\n",
        "pred['bleu1'] = pred.apply(lambda x: sentence_bleu_n(x[1], x[0], weights = [1,0,0,0]), axis=1)\n",
        "\n",
        "# bleu2\n",
        "pred['bleu2'] = pred.apply(lambda x: sentence_bleu_n(x[1], x[0], weights = [.5,.5,0,0]), axis=1)\n",
        "\n",
        "print('bleu1: {}'.format(pred['bleu1'].mean()))\n",
        "print('bleu2: {}'.format(pred['bleu2'].mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bleu1: 0.23101375794663268\n",
            "bleu2: 0.22685058114066464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKqC2rNe1rNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7e0cdd-4d7a-420b-9cb8-2a2879cf4f27"
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge \n",
        "\n",
        "# rouge1\n",
        "pred['rouge1'] = pred.apply(lambda x: Rouge().get_scores(x[0], x[1])[0]['rouge-1']['f'], axis=1)\n",
        "\n",
        "# rouge2\n",
        "pred['rouge2'] = pred.apply(lambda x: Rouge().get_scores(x[0], x[1])[0]['rouge-2']['f'], axis=1)\n",
        "\n",
        "print('rouge1: {}'.format(pred['rouge1'].mean()))\n",
        "print('rouge2: {}'.format(pred['rouge2'].mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n",
            "rouge1: 0.32601084529658725\n",
            "rouge2: 0.20070894004695408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuzaa9yc13mb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}